---
title: é¢„æµ‹è¯•å·3& 23
slug: QQqNwziPmiYyFBknLftcE8vWnLb/AlHCwR5LUiW2VDkuzaTc8KsQnsf
sidebar_position: 1
---


# é¢„æµ‹è¯•å·3& 23

å½“ç„¶å¯ä»¥ï¼Œäº‘é›ã€‚æˆ‘ç»™ä½ å‡†å¤‡ä¸¤ä»½å·å­ï¼Œæ¯ä»½éƒ½ä¸¥æ ¼å›´ç»•ä½ ä¸Šä¼ çš„ Lecture 2 å’Œ Lecture 3 å†…å®¹ï¼Œé¢˜å‹è¦†ç›–ï¼š

- <b>æ¦‚å¿µé¢˜ï¼ˆçŸ­ç­”ï¼‰</b>
- <b>è®¡ç®—é¢˜ï¼ˆsupport / confidence / lift / utility / TWUï¼‰</b>
- <b>ç®—æ³•é¢˜ï¼ˆApriori / ExtractRules / HUIï¼‰</b>
- <b>ç»¼åˆåº”ç”¨é¢˜</b>
    
æ‰€æœ‰é¢˜ç›®éƒ½ç”¨è‹±æ–‡ï¼ˆå› ä¸ºä½ æ˜¯è‹±è¯­è€ƒè¯•ï¼‰ï¼Œä½†æˆ‘ä¼šç¡®ä¿é¢˜ç›®é£æ ¼å®Œå…¨è´´åˆè€å¸ˆçš„å‡ºé¢˜æ–¹å¼ã€‚

---

# ğŸ“˜ <b>Exam Paper 1 â€” Lecture 3 Onlyï¼ˆAffinity Mining II ä¸“é¢˜å·ï¼‰</b>

## <b>Part A â€” Short Concept Questions</b>

1. Define <em>association rule mining</em> and explain its goal in the context of affinity mining.  
2. What is the definition of <em>confidence</em> for a rule \(A \rightarrow B\)?  
3. What makes an association rule *strong*?  
4. Explain the purpose of the <em>ExtractRules</em> procedure.  
5. What is <em>lift</em> and how is it interpreted?  
6. Why is <em>Apriori</em> not applicable to High Utility Itemset Mining (HUI)?  
7. Define *local utility*, *global utility*, and *transactional utility*.  
8. What is <em>Transaction-Weighted Utility (TWU)</em> and why is it important?
    
---

## <b>Part B â€” Calculation Questions</b>

### <b>Q9. Confidence Calculation</b>

Given:

- support({A}) = 0.6  
- support({A,B}) = 0.3  
    
Compute the confidence of the rule:

\[

A \rightarrow B

\]

---

### <b>Q10. Lift Calculation</b>

Given:

- support({A}) = 0.5  
- support({B}) = 0.4  
- support({A,B}) = 0.3  
    
Compute:

\[

\text{lift}(A,B)

\]

---

### <b>Q11. Utility Calculation</b>

Global utilities:

<table>
<colgroup>
<col width="200"/>
<col width="200"/>
</colgroup>
<tbody>
<tr><td><p>Item</p></td><td><p>Utility</p></td></tr>
<tr><td><p>X</p></td><td><p>3</p></td></tr>
<tr><td><p>Y</p></td><td><p>5</p></td></tr>
</tbody>
</table>

Transaction T1 contains:

- (X, 2)  
- (Y, 1)
    
Compute:

1. \(u(X, T1)\)  
2. \(u(Y, T1)\)  
3. \(u(\{X,Y\}, T1)\)
    
---

### <b>Q12. Transaction Weight</b>

Given transaction T2:

- (A, 1), (B, 2), (C, 1)
    
Global utilities:

- A: 2  
- B: 3  
- C: 1  
    
Compute the transaction weight:

\[

w_2 = \sum u(a_j, T_2)

\]

---

## <b>Part C â€” Algorithm Questions</b>

### <b>Q13. ExtractRules</b>

Given frequent itemset:

\[

f = \{A, B, C\}

\]

List all possible rules generated by ExtractRules (do not compute confidence).

---

### <b>Q14. HUI Identification</b>

Given:

- Umin = 20  
- u({A,B}) = 18  
- u({A,C}) = 25  
- u({B,C}) = 22  
    
Which itemsets are HUIs?

---

### <b>Q15. TWU Pruning</b>

Given:

- TWU({A}) = 50  
- TWU({A,B}) = 30  
- TWU({A,B,C}) = 10  
- Umin = 20  
    
Which itemsets survive TWU pruning?

---

---

# ğŸ“˜ <b>Exam Paper 2 â€” Lecture 2 + Lecture 3 ç»¼åˆå·</b>

## <b>Part A â€” Short Concept Questions</b>

1. Define <em>support</em> and *frequent itemset*.  
2. Define <em>confidence</em> and *strong rule*.  
3. State the <em>Apriori principle</em> and explain why it is useful.  
4. Describe the main steps of the *Apriori algorithm*.  
5. Explain the difference between <em>frequent itemset mining</em> and *association rule mining*.  
6. What is <em>lift</em> and why is it used?  
7. Why does Apriori fail for High Utility Itemset Mining?  
8. What is *Transaction-Weighted Downward Closure*?
    
---

## <b>Part B â€” Support & Confidence Calculations</b>

### <b>Q9. Support Calculation</b>

Database:

<table>
<colgroup>
<col width="200"/>
<col width="200"/>
</colgroup>
<tbody>
<tr><td><p>TID</p></td><td><p>Items</p></td></tr>
<tr><td><p>1</p></td><td><p>A, B</p></td></tr>
<tr><td><p>2</p></td><td><p>A, C</p></td></tr>
<tr><td><p>3</p></td><td><p>B, C</p></td></tr>
<tr><td><p>4</p></td><td><p>A, B, C</p></td></tr>
<tr><td><p>5</p></td><td><p>A</p></td></tr>
</tbody>
</table>

Compute:

1. support(A)  
2. support(B)  
3. support(C)  
4. support({A,B})  
5. support({A,C})
    
---

### <b>Q10. Confidence</b>

Compute:

\[

\text{conf}(A \rightarrow B)

\]

using your results from Q9.

---

## <b>Part C â€” Apriori Algorithm</b>

### <b>Q11. Generate C2 and F2</b>

Given:

\[

F_1 = \{A, B, C\},\quad S_{\min} = 0.4

\]

1. Generate \(C_2\)  
2. Compute support  
3. Determine \(F_2\)
    
---

### <b>Q12. Generate C3</b>

Using your F2 from Q11:

1. Generate C3  
2. Apply Apriori pruning  
3. Determine whether any 3â€‘itemset is frequent
    
---

## <b>Part D â€” Association Rule Mining</b>

### <b>Q13. Extract Strong Rules</b>

Given:

<table>
<colgroup>
<col width="200"/>
<col width="200"/>
</colgroup>
<tbody>
<tr><td><p>Itemset</p></td><td><p>Support</p></td></tr>
<tr><td><p>{A}</p></td><td><p>0.7</p></td></tr>
<tr><td><p>{B}</p></td><td><p>0.5</p></td></tr>
<tr><td><p>{A,B}</p></td><td><p>0.4</p></td></tr>
</tbody>
</table>

Cmin = 0.6

Find all strong rules.

---

### <b>Q14. Lift Calculation</b>

Given:

- support(A) = 0.7  
- support(B) = 0.5  
- support(A,B) = 0.4  
    
Compute lift(A,B).

---

## <b>Part E â€” High Utility Itemset Mining</b>

### <b>Q15. Utility Calculation</b>

Global utilities:

<table>
<colgroup>
<col width="200"/>
<col width="200"/>
</colgroup>
<tbody>
<tr><td><p>Item</p></td><td><p>Utility</p></td></tr>
<tr><td><p>A</p></td><td><p>2</p></td></tr>
<tr><td><p>B</p></td><td><p>4</p></td></tr>
</tbody>
</table>

Transaction T1:

- (A, 3), (B, 1)
    
Compute:

1. u(A, T1)  
2. u(B, T1)  
3. u({A,B}, T1)
    
---

### <b>Q16. TWU Calculation</b>

Given:

<table>
<colgroup>
<col width="200"/>
<col width="200"/>
</colgroup>
<tbody>
<tr><td><p>TID</p></td><td><p>Transaction Weight</p></td></tr>
<tr><td><p>1</p></td><td><p>5</p></td></tr>
<tr><td><p>2</p></td><td><p>12</p></td></tr>
<tr><td><p>3</p></td><td><p>7</p></td></tr>
</tbody>
</table>

Itemset {A,B} appears in T1 and T3.

Compute:

\[

TWU(\{A,B\})

\]

---

### <b>Q17. HUI Identification</b>

Given:

- Umin = 15  
- u({A,B}) = 12  
- u({A,C}) = 18  
- u({B,C}) = 20  
    
Which itemsets are HUIs?

---

# å¦‚æœä½ æ„¿æ„ï¼Œæˆ‘å¯ä»¥ç»§ç»­ä¸ºä½ ï¼š

- <b>æä¾›ä¸¤ä»½å·å­çš„æ ‡å‡†ç­”æ¡ˆï¼ˆè‹±æ–‡ï¼‰</b>  
- <b>åšä¸€ä»½â€œLecture 2 + 3 ä¸€é¡µçº¸é€Ÿè®°ç‰ˆâ€</b>  
- <b>åšä¸€ä»½â€œé«˜é¢‘è€ƒç‚¹æ€»ç»“ + é¢„æµ‹é¢˜â€</b>  
- <b>åšä¸€ä»½â€œæ‰‹ç®—é¢˜ä¸“é¡¹è®­ç»ƒâ€</b>
    
ä½ æƒ³è¦å“ªä¸€ä¸ªï¼Ÿ

