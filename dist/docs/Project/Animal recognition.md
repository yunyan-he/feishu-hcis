---
title: Animal recognition
slug: WOFlwSfzfiJbX3kcEvdcidK3nCc/Vd23wqXwgidXUnkjLr3cbLN1nXb
sidebar_position: 0
---


# Animal recognition

# Pytorch

## Python pytorch fastai

Pytorch is a library.

Fastai is also a library, but uses Pytorch under the hood

<b>Fastai encapsulates higher level interfaces on top of Pytorch</b>

## Data process

### In pytorch

<b>åœ¨ PyTorch ä¸­ï¼Œæ•°æ®å¤„ç†ä¸»è¦ä¾èµ– </b><b>Dataset</b><b> å’Œ </b><b>DataLoader</b><b> ä¸¤ä¸ªæ ¸å¿ƒç»„ä»¶ï¼Œç”¨æ¥ç®¡ç†æ•°æ®é›†ã€æ‰¹é‡åŠ è½½ã€é¢„å¤„ç†å’Œå¢å¼ºã€‚</b>

#### ğŸ“Œ PyTorch æ•°æ®å¤„ç†çš„æ ¸å¿ƒæœºåˆ¶

1. <b>Dataset (æ•°æ®é›†ç±»)</b>
    - `torch.utils.data.Dataset` æ˜¯ä¸€ä¸ªæŠ½è±¡ç±»ï¼Œç”¨æ¥è¡¨ç¤ºæ•°æ®é›†ã€‚
    - ä½ å¯ä»¥ä½¿ç”¨å†…ç½®æ•°æ®é›†ï¼ˆå¦‚ `MNIST`, `CIFAR10`ï¼‰ï¼Œä¹Ÿå¯ä»¥é€šè¿‡ç»§æ‰¿ `Dataset` æ¥è‡ªå®šä¹‰æ•°æ®é›†ã€‚
    - å¿…é¡»å®ç°ä¸¤ä¸ªæ–¹æ³•ï¼š 
        - `__len__()`ï¼šè¿”å›æ•°æ®é›†å¤§å°ã€‚
        - `__getitem__(idx)`ï¼šæ ¹æ®ç´¢å¼•è¿”å›ä¸€ä¸ªæ ·æœ¬ï¼ˆè¾“å…¥ + æ ‡ç­¾ï¼‰ã€‚

```py
from torch.utils.data import Dataset

class MyDataset(Dataset):
    def __init__(self, X, y):
        self.X = X
        self.y = y
    def __len__(self):
        return len(self.X)
    def __getitem__(self, idx):
        return self.X[idx], self.y[idx]
```

1. <b>DataLoader (æ•°æ®åŠ è½½å™¨)</b>
    - `torch.utils.data.DataLoader` ç”¨æ¥æŠŠ `Dataset` åŒ…è£…æˆä¸€ä¸ªå¯è¿­ä»£å¯¹è±¡ã€‚
    - æ”¯æŒ <b>æ‰¹é‡åŠ è½½ (batch)</b>ã€<b>æ‰“ä¹±æ•°æ® (shuffle)</b>ã€<b>å¤šçº¿ç¨‹åŠ è½½ (num_workers)</b>ã€‚
    - å¸¸è§ç”¨æ³•ï¼š 
    ```py
from torch.utils.data import DataLoader

dataset = MyDataset(X_data, y_data)
loader = DataLoader(dataset, batch_size=32, shuffle=True)
for batch_X, batch_y in loader:
    # è®­ç»ƒä»£ç 
```

2. <b>Transforms (æ•°æ®é¢„å¤„ç†ä¸å¢å¼º)</b>
    - å¯¹å›¾åƒæ•°æ®å¸¸ç”¨ `torchvision.transforms`ï¼š 
        - `transforms.ToTensor()`ï¼šæŠŠå›¾ç‰‡è½¬ä¸ºå¼ é‡ã€‚
        - `transforms.Normalize(mean, std)`ï¼šå½’ä¸€åŒ–ã€‚
        - `transforms.RandomHorizontalFlip()`ï¼šéšæœºæ°´å¹³ç¿»è½¬ã€‚
        - `transforms.Resize(size)`ï¼šè°ƒæ•´å¤§å°ã€‚
    - ç¤ºä¾‹ï¼š 
    ```py
from torchvision import transforms

transform = transforms.Compose([
    transforms.Resize((224,224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5], std=[0.5])
])
```

3. <b>æ ‡å‡†æ•°æ®é›†åŠ è½½</b>
    - `torchvision.datasets` æä¾›å¸¸è§æ•°æ®é›†ï¼šMNIST, CIFAR10, ImageNet ç­‰ã€‚
    - ç¤ºä¾‹ï¼š 
    ```py
from torchvision.datasets import CIFAR10

train_data = CIFAR10(root="./data", train=True, transform=transform, download=True)
train_loader = DataLoader(train_data, batch_size=64, shuffle=True)
```

---

#### âœ… æ€»ç»“

- <b>Dataset</b>ï¼šå®šä¹‰æ•°æ®é›†ç»“æ„ã€‚
- <b>DataLoader</b>ï¼šæ‰¹é‡åŠ è½½å’Œè¿­ä»£æ•°æ®ã€‚
- <b>Transforms</b>ï¼šé¢„å¤„ç†å’Œå¢å¼ºæ•°æ®ã€‚
- <b>torchvision.datasets</b>ï¼šå¿«é€Ÿè·å–å¸¸è§æ•°æ®é›†ã€‚

ğŸ‘‰ PyTorch çš„æ•°æ®å¤„ç†æµç¨‹å°±æ˜¯ï¼š<b>Dataset â†’ DataLoader â†’ Transforms â†’ æ¨¡å‹è®­ç»ƒ</b>  [docs.pytorch.org](https://docs.pytorch.org/tutorials/beginner/basics/data_tutorial.html)  [GeeksForGeeks](https://www.geeksforgeeks.org/deep-learning/data-preprocessing-in-pytorch/)  [èœé¸Ÿæ•™ç¨‹](https://www.runoob.com/pytorch/pytorch-dataset-dataloader.html)ã€‚

### In fastai

åœ¨ <b>fastai</b> ä¸­ï¼Œæ•°æ®å¤„ç†æ¯” PyTorch æ›´é«˜å±‚æ¬¡å’Œè‡ªåŠ¨åŒ–ï¼Œå®ƒå°è£…äº†å¾ˆå¤šå¸¸è§æ­¥éª¤ï¼Œè®©ä½ ç”¨æå°‘çš„ä»£ç å°±èƒ½å®Œæˆæ•°æ®åŠ è½½ã€é¢„å¤„ç†å’Œå¢å¼ºã€‚

#### ğŸ“Œ fastai æ•°æ®å¤„ç†çš„æ ¸å¿ƒæœºåˆ¶

The `DataBlock` API in FastAI is a powerful tool for this. It allows you to easily define the data sources, splits, and the various data transformations or augmentations you want to apply. You can use built - in transformers to randomly rotate images, adjust brightness, and do other operations to increase the diversity of your training data. 

1. <b>DataBlock API</b>
    - fastai çš„æ ¸å¿ƒæ•°æ®å¤„ç†å·¥å…·ã€‚
    - ç”¨æ¥å®šä¹‰æ•°æ®çš„ç»“æ„ï¼šè¾“å…¥ç±»å‹ã€æ ‡ç­¾ç±»å‹ã€å¦‚ä½•è·å–æ•°æ®ã€å¦‚ä½•åˆ†å‰²è®­ç»ƒ/éªŒè¯é›†ã€å¦‚ä½•åšé¢„å¤„ç†ã€‚
    - ç¤ºä¾‹ï¼š 
    These parameters are crucial for customizing your data processing. `blocks` define the types of data, `get_items` tells how to access the data, `splitters` divide the data into training and validation sets, `get_y` is used to get the target values, and `item_tfms` and `batch_tfms` are for applying data transformations at the item and batch levels respectively. 
    ```py
from fastai.vision.all import *

dblock = DataBlock(
    blocks=(ImageBlock, CategoryBlock),   # è¾“å…¥æ˜¯å›¾åƒï¼Œè¾“å‡ºæ˜¯ç±»åˆ«
    get_items=get_image_files,            # è·å–æ•°æ®çš„æ–¹æ³•
    splitter=RandomSplitter(valid_pct=0.2, seed=42),  # åˆ’åˆ†è®­ç»ƒ/éªŒè¯é›†
    get_y=parent_label,                   # æ ‡ç­¾æ¥æºï¼šæ–‡ä»¶å¤¹å
    item_tfms=Resize(224),                # å•æ ·æœ¬å˜æ¢
    batch_tfms=aug_transforms()           # æ‰¹é‡æ•°æ®å¢å¼º
)

dls = dblock.dataloaders(path, bs=32)
dls.show_batch(max_n=9)
```

2. <b>DataLoaders</b>
    - `dataloaders()` ä¼šè¿”å›ä¸€ä¸ª `DataLoaders` å¯¹è±¡ï¼ŒåŒ…å«è®­ç»ƒé›†å’ŒéªŒè¯é›†çš„è¿­ä»£å™¨ã€‚
    - å†…éƒ¨ä¾ç„¶åŸºäº PyTorch çš„ `DataLoader`ï¼Œä½† fastai è‡ªåŠ¨å¸®ä½ å¤„ç†å¥½ transformsã€batchã€GPU ç­‰ã€‚

3. <b>Transforms (æ•°æ®å˜æ¢ä¸å¢å¼º)</b>
    - fastai æä¾›äº†ä¸°å¯Œçš„å›¾åƒå¢å¼ºå‡½æ•°ï¼š 
        - `Resize`ï¼šè°ƒæ•´å¤§å°
        - `aug_transforms`ï¼šå¸¸ç”¨çš„éšæœºæ—‹è½¬ã€ç¼©æ”¾ã€ç¿»è½¬ã€äº®åº¦å¯¹æ¯”åº¦è°ƒæ•´ç­‰
        - `Normalize`ï¼šå½’ä¸€åŒ–
    - å¯ä»¥åˆ†åˆ«åº”ç”¨åœ¨ <b>item_tfms</b>ï¼ˆå•æ ·æœ¬çº§åˆ«ï¼‰å’Œ <b>batch_tfms</b>ï¼ˆæ‰¹é‡çº§åˆ«ï¼‰ã€‚

4. <b>å†…ç½®æ•°æ®é›†æ”¯æŒ</b>
    - fastai æä¾›äº†å¾ˆå¤šç°æˆçš„æ•°æ®é›†åŠ è½½å™¨ï¼Œæ¯”å¦‚ `ImageDataLoaders.from_folder()`ã€`TextDataLoaders.from_folder()`ï¼Œåªéœ€ä¸€è¡Œä»£ç å³å¯å®Œæˆæ•°æ®å‡†å¤‡ã€‚
    - ç¤ºä¾‹ï¼š 
    ```py
dls = ImageDataLoaders.from_folder(path, valid_pct=0.2, bs=32)
```

---

#### ğŸ“Š PyTorch vs fastai æ•°æ®å¤„ç†å¯¹æ¯”

---

#### âœ… æ€»ç»“

- åœ¨ PyTorch ä¸­ï¼Œæ•°æ®å¤„ç†éœ€è¦ä½ æ‰‹åŠ¨å†™å¾ˆå¤šç±»å’Œå‡½æ•°ã€‚
- åœ¨ fastai ä¸­ï¼Œæ•°æ®å¤„ç†é€šè¿‡ <b>DataBlock API</b> å’Œ <b>DataLoaders</b> é«˜åº¦å°è£…ï¼Œå‡ è¡Œä»£ç å°±èƒ½å®Œæˆã€‚
- fastai çš„ä¼˜åŠ¿æ˜¯ <b>å¿«é€Ÿå®éªŒ</b>ï¼Œç‰¹åˆ«é€‚åˆåŸå‹å¼€å‘å’Œæ•™å­¦ã€‚

## Model building

### In pytorch

åœ¨ <b>PyTorch</b> ä¸­ï¼Œæ„å»ºæ¨¡å‹ï¼ˆmodel buildï¼‰é€šå¸¸åˆ†ä¸ºå‡ ä¸ªå…³é”®æ­¥éª¤ï¼š

---

#### å®šä¹‰æ¨¡å‹ç»“æ„

- ä½¿ç”¨ `torch.nn.Module` æ¥åˆ›å»ºè‡ªå®šä¹‰æ¨¡å‹ã€‚
- åœ¨ `init` æ–¹æ³•ä¸­å®šä¹‰å±‚ï¼ˆlayersï¼‰ï¼Œåœ¨ `forward` æ–¹æ³•ä¸­å®šä¹‰å‰å‘ä¼ æ’­é€»è¾‘ã€‚

```py
import torch
import torch.nn as nn
import torch.nn.functional as F

class SimpleNet(nn.Module):
    def __init__(self):
        super(SimpleNet, self).__init__()
        # å®šä¹‰å±‚
        self.fc1 = nn.Linear(784, 128)   # è¾“å…¥å±‚ â†’ éšè—å±‚
        self.fc2 = nn.Linear(128, 64)    # éšè—å±‚ â†’ éšè—å±‚
        self.fc3 = nn.Linear(64, 10)     # éšè—å±‚ â†’ è¾“å‡ºå±‚

    def forward(self, x):
        # å‰å‘ä¼ æ’­
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)   # è¾“å‡ºå±‚ä¸åŠ æ¿€æ´»ï¼Œäº¤ç»™ loss function
        return x
```

---

#### åˆå§‹åŒ–æ¨¡å‹

```py
model = SimpleNet()
print(model)
```

---

#### å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨

- æŸå¤±å‡½æ•°ï¼šå¦‚äº¤å‰ç†µ `nn.CrossEntropyLoss()`
- ä¼˜åŒ–å™¨ï¼šå¦‚ SGD æˆ– Adam

```py
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
```

---

### In fastai

In FastAI, you can use pre - built architectures like those from the `vision.models` library. You first choose a suitable architecture, then customize it according to your task. After that, you wrap it up into a `Learner` object which combines the model, data, optimizer, and loss function. This way, you can start training your model easily.

åœ¨ fastai ä¸­ï¼Œæ¨¡å‹å®šä¹‰é€šå¸¸æ˜¯é€šè¿‡ <b>Learner API</b> æ¥å®Œæˆçš„ã€‚ä½ ä¸éœ€è¦è‡ªå·±å†™ `nn.Module`ï¼Œè€Œæ˜¯ç›´æ¥è°ƒç”¨é¢„å®šä¹‰çš„æ¶æ„ï¼ˆæ¥è‡ª PyTorch çš„ `torchvision.models`ï¼‰ï¼Œfastai ä¼šå¸®ä½ å°è£…å¥½ï¼š

```text
from fastai.vision.all import *

# ä½¿ç”¨ ResNet18 ä½œä¸º backbone
learn = vision_learner(dls, resnet18, metrics=accuracy)
```

- `vision_learner` ä¼šè‡ªåŠ¨ï¼š
    - åŠ è½½é¢„è®­ç»ƒçš„ ResNet18ï¼ˆæ¥è‡ª PyTorchï¼‰
    - æ›¿æ¢æœ€åä¸€å±‚ä¸ºé€‚åˆä½ æ•°æ®é›†çš„è¾“å‡ºå±‚
    - å°è£…æˆä¸€ä¸ª `Learner` å¯¹è±¡ï¼Œåç»­å¯ä»¥ç›´æ¥è®­ç»ƒå’Œè¯„ä¼°

ğŸ‘‰ åœ¨ fastai ä¸­ï¼Œæ¨¡å‹å®šä¹‰å°±æ˜¯ <b>é€‰æ‹©ä¸€ä¸ª backbone + fastai è‡ªåŠ¨å°è£…</b>ï¼Œå‡ è¡Œä»£ç å³å¯å®Œæˆã€‚

### 1. `model` parameter

This is the actual neural network architecture you choose. For instance, you can use pre - trained models like `resnet18`, `resnet34`, `resnet50` etc. These models have been trained on large - scale datasets like ImageNet, and they can be fine - tuned for your specific task.

```py
from fastai.vision.all import *
data = ImageDataBunch.from_folder(path='.')
learn = vision_learner(data, resnet18, metrics=[accuracy])
```

In this code, `resnet18` is passed as the `model` parameter to `vision_learner`.

### 2. `data` parameter

This is the `ImageDataBunch` object that you've prepared earlier using `DataBlock`. It contains your training, validation (and optionally test) datasets, along with information on how to pre - process and augment the data. The `ImageDataBunch` takes care of things like normalizing the images according to the statistics of your dataset.

### 3. `metrics` parameter

This is used to define the evaluation metrics you want to track during training and validation. For classification tasks, common metrics are `accuracy`, `precision`, `recall`, and `F1 - score`. You can pass multiple metrics as a list.

```py
from fastai.vision.all import *
data = ImageDataBunch.from_folder(path='.')
learn = vision_learner(data, resnet18, metrics=[accuracy, precision])
```

Here, both `accuracy` and `precision` will be calculated during training and validation.

### 4. `opt_func` parameter

This specifies the optimizer you want to use. FastAI has several built - in optimizers like `sgd` (Stochastic Gradient Descent), `adam`, etc. The default optimizer is `adam`.

```py
from fastai.vision.all import *
data = ImageDataBunch.from_folder(path='.')
learn = vision_learner(data, resnet18, metrics=[accuracy], opt_func=sgd)
```

In this example, the `sgd` optimizer is used instead of the default.

### 5. `loss_func` parameter

This is the loss function. For image classification, the default loss function is `CrossEntropyLoss`. But if you have a specific problem, you can choose other loss functions.

```py
from fastai.vision.all import *import torch.nn as nn
data = ImageDataBunch.from_folder(path='.')
loss_func = nn.CrossEntropyLoss()
learn = vision_learner(data, resnet18, metrics=[accuracy], loss_func=loss_func)
```

These are some of the main parameters when using `vision_learner` in FastAI. Each one plays a crucial role in building, training, and evaluating your vision - based machine - learning models.

## Model Training

### In pytorch

#### è®­ç»ƒå¾ªç¯

- å‰å‘ä¼ æ’­ â†’ è®¡ç®—æŸå¤± â†’ åå‘ä¼ æ’­ â†’ æ›´æ–°å‚æ•°

```py
for epoch in range(10):  # è®­ç»ƒ 10 ä¸ª epoch
    for inputs, labels in train_loader:
        # å‰å‘ä¼ æ’­
        outputs = model(inputs)
        loss = criterion(outputs, labels)

        # åå‘ä¼ æ’­
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

    print(f"Epoch {epoch+1}, Loss: {loss.item()}")
```

---

### In fastai

åœ¨ <b>fastai</b> ä¸­ï¼Œæ¨¡å‹è®­ç»ƒæ˜¯å®ƒæœ€å¤§çš„ä¼˜åŠ¿ä¹‹ä¸€ï¼šç›¸æ¯” PyTorch éœ€è¦æ‰‹å†™è®­ç»ƒå¾ªç¯ï¼Œfastai æä¾›äº†é«˜åº¦å°è£…çš„ <b>Learner API</b>ï¼Œåªéœ€å‡ è¡Œä»£ç å°±èƒ½å®Œæˆå®Œæ•´çš„è®­ç»ƒè¿‡ç¨‹ã€‚

---

#### fastai æ¨¡å‹è®­ç»ƒçš„æ ¸å¿ƒæ–¹æ³•

1. <b>fit()</b>
    - åŸºç¡€è®­ç»ƒæ–¹æ³•ï¼Œè¿è¡ŒæŒ‡å®šçš„ epoch æ•°ã€‚

```py
learn.fit(5)   # è®­ç»ƒ 5 ä¸ª epoch
```

1. <b>fine_tune()</b>
    - ç”¨äºè¿ç§»å­¦ä¹ ï¼šå…ˆå†»ç»“é¢„è®­ç»ƒæ¨¡å‹çš„å‰å‡ å±‚ï¼Œåªè®­ç»ƒæœ€åçš„åˆ†ç±»å±‚ï¼Œç„¶åå†è§£å†»å…¨éƒ¨å±‚ç»§ç»­è®­ç»ƒã€‚

```py
learn.fine_tune(5)   # è¿ç§»å­¦ä¹ è®­ç»ƒ 5 ä¸ª epoch
```

1. <b>fit_one_cycle()</b>
    - ä½¿ç”¨ <b>1cycle å­¦ä¹ ç‡ç­–ç•¥</b>ï¼ˆä¸€ç§åŠ¨æ€è°ƒæ•´å­¦ä¹ ç‡çš„æ–¹æ³•ï¼Œå¸¸å¸¸èƒ½æå‡æ•ˆæœï¼‰ã€‚

```py
learn.fit_one_cycle(10, lr_max=1e-3)   # è®­ç»ƒ 10 ä¸ª epochï¼Œæœ€å¤§å­¦ä¹ ç‡ 0.001
```

1. <b>å­¦ä¹ ç‡æŸ¥æ‰¾ (lr_find)</b>
    - è‡ªåŠ¨å¯»æ‰¾åˆé€‚çš„å­¦ä¹ ç‡èŒƒå›´ã€‚

```py
learn.lr_find()
```

1. <b>å›è°ƒ (Callbacks)</b>
    - fastai æä¾›äº†å¾ˆå¤šè®­ç»ƒè¿‡ç¨‹ä¸­çš„å›è°ƒï¼Œæ¯”å¦‚ï¼š 
        - `EarlyStoppingCallback`ï¼šéªŒè¯é›† loss ä¸å†ä¸‹é™æ—¶æå‰åœæ­¢ã€‚
        - `SaveModelCallback`ï¼šä¿å­˜æœ€ä½³æ¨¡å‹ã€‚

```py
from fastai.callback.tracker import EarlyStoppingCallback, SaveModelCallback

learn.fine_tune(10, cbs=[EarlyStoppingCallback(monitor='valid_loss', patience=3),
                         SaveModelCallback(monitor='accuracy')])
```

---

#### ğŸ“Š PyTorch vs fastai è®­ç»ƒå¯¹æ¯”

---

#### âœ… æ€»ç»“

åœ¨ fastai ä¸­ï¼Œæ¨¡å‹è®­ç»ƒå°±æ˜¯ï¼š

- <b>å®šä¹‰ Learner â†’ è°ƒç”¨ fit/fine_tune â†’ å¯é€‰å›è°ƒå’Œå­¦ä¹ ç‡æŸ¥æ‰¾</b>  
 å‡ è¡Œä»£ç å³å¯å®Œæˆå®Œæ•´çš„è®­ç»ƒæµç¨‹ã€‚

You pointed out that FastAI simplifies a lot compared to PyTorch. In PyTorch, you have to manually set up the optimizer, loss function, and handle backpropagation. But with FastAI's `Learner` class, you can achieve these tasks with much simpler code. Also, you're correct that FastAI makes transfer learning easy. It allows you to use pre-trained models and adapt them for your specific tasks.

## Model evaluation

### In pytorch

- åœ¨éªŒè¯é›†æˆ–æµ‹è¯•é›†ä¸Šè¿è¡Œå‰å‘ä¼ æ’­ï¼Œä¸è¿›è¡Œæ¢¯åº¦æ›´æ–°ã€‚

```py
model.eval()
with torch.no_grad():
    correct = 0
    total = 0
    for inputs, labels in test_loader:
        outputs = model(inputs)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print(f"Accuracy: {100 * correct / total:.2f}%")
```

---

#### In fastai

åœ¨ <b>fastai</b> ä¸­ï¼Œæ¨¡å‹è¯„ä¼°ï¼ˆevaluationï¼‰åŒæ ·æ˜¯é«˜åº¦å°è£…çš„ï¼Œä½ ä¸ç”¨åƒåœ¨ PyTorch é‚£æ ·æ‰‹å†™æµ‹è¯•å¾ªç¯ã€‚fastai æä¾›äº†å¤šç§æ–¹æ³•æ¥æ£€æŸ¥æ¨¡å‹æ€§èƒ½ã€å¯è§†åŒ–ç»“æœå’Œè§£é‡Šé”™è¯¯ã€‚

---

#### ğŸ“Œ å¸¸ç”¨çš„æ¨¡å‹è¯„ä¼°æ–¹æ³•

1. <b>è¯„ä¼°æŒ‡æ ‡ (Metrics)</b>
    - åœ¨å®šä¹‰ `Learner` æ—¶å°±å¯ä»¥æŒ‡å®šè¯„ä¼°æŒ‡æ ‡ï¼Œä¾‹å¦‚ `accuracy`ã€`error_rate` ç­‰ã€‚
    - è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šè‡ªåŠ¨æ˜¾ç¤ºè¿™äº›æŒ‡æ ‡ã€‚

```py
learn = vision_learner(dls, resnet18, metrics=accuracy)
```

1. <b>éªŒè¯é›†è¯„ä¼°</b>
    - ä½¿ç”¨ `learn.validate()` åœ¨éªŒè¯é›†ä¸Šè¿è¡Œä¸€æ¬¡è¯„ä¼°ï¼Œè¿”å› loss å’ŒæŒ‡æ ‡ã€‚

```py
learn.validate()
```

1. <b>é¢„æµ‹ (Prediction)</b>
    - å•æ ·æœ¬é¢„æµ‹ï¼š 
    ```py
pred, pred_idx, probs = learn.predict("test_image.jpg")
print(pred, pred_idx, probs)
```
    - æ‰¹é‡é¢„æµ‹ï¼š 
    ```py
preds, targets = learn.get_preds()
```

2. <b>ç»“æœå±•ç¤º</b>
    - å¿«é€ŸæŸ¥çœ‹æ¨¡å‹åœ¨éªŒè¯é›†ä¸Šçš„é¢„æµ‹ç»“æœï¼š 
    ```py
learn.show_results()
```

3. <b>æ¨¡å‹è§£é‡Š (Interpretation)</b>
    - fastai æä¾›äº† `ClassificationInterpretation` æ¥åˆ†æé”™è¯¯åˆ†ç±»ï¼š 
    ```py
from fastai.interpret import ClassificationInterpretation
interp = ClassificationInterpretation.from_learner(learn)
interp.plot_top_losses(9, figsize=(7,7))   # æ˜¾ç¤ºæŸå¤±æœ€å¤§çš„æ ·æœ¬
interp.plot_confusion_matrix(figsize=(6,6)) # æ··æ·†çŸ©é˜µ
interp.most_confused()                      # æœ€å¸¸è§çš„é”™è¯¯ç±»åˆ«å¯¹
```

---

#### ğŸ“Š PyTorch vs fastai æ¨¡å‹è¯„ä¼°å¯¹æ¯”

---

#### âœ… æ€»ç»“

åœ¨ fastai ä¸­ï¼Œæ¨¡å‹è¯„ä¼°å°±æ˜¯ï¼š

- <b>metrics è‡ªåŠ¨è·Ÿè¸ª</b>
- <b>validate() ä¸€è¡Œè¯„ä¼°</b>
- <b>predict() å¿«é€Ÿé¢„æµ‹</b>
- <b>show_results + Interpretation å¯è§†åŒ–å’Œé”™è¯¯åˆ†æ</b>

ğŸ‘‰ å®ƒæŠŠ PyTorch ä¸­éœ€è¦å‡ åè¡Œä»£ç çš„è¯„ä¼°è¿‡ç¨‹ï¼Œç®€åŒ–æˆå‡ è¡Œå³å¯å®Œæˆã€‚

## Model save

In PyTorch, you can save a model's state dictionary using `torch.save`. For example, if your model is named `model`, you'd do something like `torch.save(model.state_dict, "model.pth")`. To load it back, you first create an instance of the same model class, then use `model.load_state_dict(torch.load`

