# **MMDI è€ƒè¯•å†²åˆºæŒ‡å—ï¼šLecture 1 & 2 (Affinity Mining)**

é’ˆå¯¹è€å¸ˆâ€œéé»‘å³ç™½â€çš„è¯„åˆ†é£æ ¼ï¼Œæœ¬æŒ‡å—å¼ºè°ƒ**ä¸“ä¸šæœ¯è¯­çš„ç²¾å‡†ä½¿ç”¨**ä¸**è®¡ç®—æ­¥éª¤çš„è§„èŒƒåŒ–**ã€‚

## **ğŸ… Part Aï¼šå¿…è€ƒæ ¸å¿ƒæ¦‚å¿µ (Core Concepts)**

### **Q1. Define support and confidence in association rule mining.**

Standard Answer:  
Support measures how frequently an itemset appears in the transactional database.  
$$\\text{support}(A) \= \\frac{\\\#\\text{transactions containing } A}{n}$$  
**Confidence** measures the empirical conditional probability of the rule

$$A \\rightarrow B$$  
.

$$\\text{confidence}(A \\rightarrow B) \= \\frac{\\text{support}(A \\cup B)}{\\text{support}(A)}$$

### **Q2. What is the "Apriori Principle"? Why is it crucial for scalability?**

Standard Answer:  
The Apriori Principle states that:  
If an itemset is frequent, then all of its non-empty subsets must also be frequent.

Alternatively (Anti-monotone property):

If an itemset is infrequent, all of its supersets must also be infrequent.

**Cruciality:** It allows the algorithm to **prune** (eliminate) a vast number of candidate itemsets without scanning the database, significantly reducing the search space and improving **scalability**.

### **Q3. Explain the difference between Descriptive and Predictive Data Mining.**

**Standard Answer:**

* **Descriptive Data Mining:** Focuses on finding human-interpretable patterns and relationships in data (e.g., Affinity Mining, Clustering).  
* **Predictive Data Mining:** Focuses on using known patterns to predict future or unknown values (e.g., Classification, Regression).

## **ğŸ…‘ Part Bï¼šè®¡ç®—å®æˆ˜é¢˜ (Calculation Practice)**

Database Scenario:  
| TID | Items |  
| :--- | :--- |  
| 1 | A, B |  
| 2 | A, C |  
| 3 | B, C |  
| 4 | A, B, C |  
| 5 | A |

### **Q4. Compute the support for each 1-itemset. (Total**

$$n \= 5$$  
)

**Standard Answer:**

* $$\\text{support}(\\{A\\}) \= \\frac{4}{5} \= 0.8$$  
* $$\\text{support}(\\{B\\}) \= \\frac{3}{5} \= 0.6$$  
* $$\\text{support}(\\{C\\}) \= \\frac{3}{5} \= 0.6$$

### **Q5. Assume**

$$S\_{\\min} \= 0.4$$  
. Identify Frequent 2-itemsets (

$$F\_2$$  
).

**Standard Answer:**

* $$\\text{support}(\\{A, B\\}) \= \\frac{2}{5} \= 0.4$$  
  ($$\\ge 0.4$$  
  , Frequent)  
* $$\\text{support}(\\{A, C\\}) \= \\frac{2}{5} \= 0.4$$  
  ($$\\ge 0.4$$  
  , Frequent)  
* $$\\text{support}(\\{B, C\\}) \= \\frac{2}{5} \= 0.4$$  
  ($$\\ge 0.4$$  
  , Frequent)  
  $$F\_2 \= \\{ \\{A,B\\}, \\{A,C\\}, \\{B,C\\} \\}$$

### **Q6. Compute the confidence of rule**

$$B \\rightarrow A$$  
.

Standard Answer:

$$\\text{confidence}(B \\rightarrow A) \= \\frac{\\text{support}(A \\cup B)}{\\text{support}(B)} \= \\frac{0.4}{0.6} \\approx 0.67$$

## **ğŸ…’ Part Cï¼šApriori ç®—æ³•æµç¨‹ (Algorithm Workflow)**

### **Q7. Using**

$$F\_2 \= \\{ \\{A,B\\}, \\{A,C\\}, \\{B,C\\} \\}$$  
, generate candidate

$$C\_3$$  
and perform the Prune step.

**Standard Answer:**

1. **Join Step:** Combine itemsets in$$F\_2$$  
   to form$$C\_3 \= \\{ \\{A, B, C\\} \\}$$  
   .  
2. **Prune Step:** Check all 2-subsets of$$\\{A, B, C\\}$$  
   :  
   * Subset$$\\{A, B\\} \\in F\_2$$  
     (Frequent)  
   * Subset$$\\{A, C\\} \\in F\_2$$  
     (Frequent)  
   * Subset$$\\{B, C\\} \\in F\_2$$  
     (Frequent)  
3. **Result:** Since all subsets are frequent, we keep$$\\{A, B, C\\}$$  
   in$$C\_3$$  
   .

## **ğŸ…“ Part Dï¼šå¼ºå…³è”è§„åˆ™åˆ¤æ–­ (Strong Rules)**

### **Q8. Let**

$$S\_{\\min} \= 0.4$$  
and

$$C\_{\\min} \= 0.6$$  
. Is the rule

$$A \\rightarrow B$$  
a "Strong Rule"?

**Standard Answer:**

1. **Check Support:**$$\\text{support}(\\{A, B\\}) \= 0.4$$  
   . Since$$0.4 \\ge S\_{\\min}$$  
   , the itemset is frequent.  
2. **Check Confidence:**$$\\text{confidence}(A \\rightarrow B) \= \\frac{0.4}{0.8} \= 0.5$$  
   .  
3. **Conclusion:** Since$$0.5 \< C\_{\\min}$$  
   , the rule$$A \\rightarrow B$$  
   is **NOT** a strong rule.

## **ğŸ…” è€ƒå‰é¿å‘å°è´´å£« (Tips for "Binary Grading" Style)**

1. **Don't skip steps:** å³ä½¿è®¡ç®—å¾ˆç®€å•ï¼Œä¹Ÿè¦å†™å‡ºå…·ä½“çš„å…¬å¼ä»£å…¥è¿‡ç¨‹ï¼Œå¦‚$$\\frac{0.4}{0.8} \= 0.5$$  
   ã€‚  
2. **Notation matters:** é›†åˆè®°å¾—åŠ èŠ±æ‹¬å·$$\\{A, B\\}$$  
   ï¼Œè§„åˆ™ä½¿ç”¨ç®­å¤´$$A \\rightarrow B$$  
   ã€‚  
3. **Terminology:** å¦‚æœé¢˜ç›®é—®ä¸ºä»€ä¹ˆèƒ½å‡å°‘è®¡ç®—ï¼Œä¸€å®šè¦å›ç­” **"Pruning the search space"**ã€‚  
4. **Thresholds:** ä¸¥æ ¼æ£€æŸ¥æ˜¯å¦**å¤§äºç­‰äº**é˜ˆå€¼ï¼Œåˆšå¥½ç­‰äºé˜ˆå€¼é€šå¸¸ä¹Ÿå±äºé¢‘ç¹é¡¹é›†ã€‚